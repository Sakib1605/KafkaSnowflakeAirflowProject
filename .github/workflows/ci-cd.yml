name: CI-CD Pipeline for Streaming Analytics Project

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

env:
  DBT_PROFILES_DIR: ./uber_dbt

jobs:

  # =============================================================
  # 1Ô∏è‚É£ PYTHON LINTING
  # =============================================================
  lint_python:
    name: Validate Python Code
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: pip install -r docker/requirements.txt || true

      - name: Run Flake8 Linting
        run: |
          pip install flake8
          flake8 simulation storage docker/dags || true



  # =============================================================
  # 2Ô∏è‚É£ DBT TESTING
  # =============================================================
  test_dbt:
    name: Test dbt Models
    runs-on: ubuntu-latest
    needs: lint_python

    steps:
      - uses: actions/checkout@v3

      - name: Install dbt
        run: pip install dbt-snowflake

      # Minimal + correct Snowflake profile
      - name: Configure dbt profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          snowflake_profile:
            target: prod
            outputs:
              prod:
                type: snowflake
                account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
                user: ${{ secrets.SNOWFLAKE_USER }}
                password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                role: ${{ secrets.SNOWFLAKE_ROLE }}
                warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
                database: ${{ secrets.SNOWFLAKE_DATABASE }}

                # üëá IMPORTANT:
                # CI must read sources from BRONZE
                # dbt models will still build into TRANSFORM automatically
                schema: BRONZE
          EOF

      - name: dbt compile
        working-directory: uber_dbt
        run: dbt compile

      - name: dbt test
        working-directory: uber_dbt
        run: dbt test



  # =============================================================
  # 3Ô∏è‚É£ DOCKER BUILD ‚Äî Local Airflow Validation Only
  # =============================================================
  docker_build:
    name: Build Airflow Docker Image
    runs-on: ubuntu-latest
    needs: test_dbt

    steps:
      - uses: actions/checkout@v3

      - name: Build Airflow Image
        run: |
          docker build -t uber-airflow:latest docker/



  # =============================================================
  # 4Ô∏è‚É£ PACKAGE DAGs (for local Airflow)
  # =============================================================
  package_dags:
    name: Package DAGs
    runs-on: ubuntu-latest
    needs: docker_build

    steps:
      - uses: actions/checkout@v3

      - name: Upload DAG Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: airflow-dags
          path: docker/dags/



  # =============================================================
  # 5Ô∏è‚É£ DBT DEPLOYMENT ‚Äî Build Gold Layer in TRANSFORM
  # =============================================================
  deploy_dbt:
    name: Deploy dbt to Snowflake
    runs-on: ubuntu-latest
    needs: package_dags

    steps:
      - uses: actions/checkout@v3

      - name: Install dbt
        run: pip install dbt-snowflake

      - name: Configure dbt profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          snowflake_profile:
            target: prod
            outputs:
              prod:
                type: snowflake
                account: ${{ secrets.SNOWFLAKE_ACCOUNT }}
                user: ${{ secrets.SNOWFLAKE_USER }}
                password: ${{ secrets.SNOWFLAKE_PASSWORD }}
                role: ${{ secrets.SNOWFLAKE_ROLE }}
                warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
                database: ${{ secrets.SNOWFLAKE_DATABASE }}

                # üëá dbt build stage (deploy) should run models into TRANSFORM
                schema: TRANSFORM
          EOF

      - name: Run dbt run (Gold Layer)
        working-directory: uber_dbt
        run: dbt run

      - name: Run dbt docs generate
        working-directory: uber_dbt
        run: dbt docs generate



  # =============================================================
  # 6Ô∏è‚É£ Pipeline Completed
  # =============================================================
  notify:
    name: Notify Completion
    runs-on: ubuntu-latest
    needs: deploy_dbt

    steps:
      - name: Print success message
        run: echo "CI/CD pipeline executed successfully!"
